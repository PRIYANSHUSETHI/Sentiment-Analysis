# -*- coding: utf-8 -*-
"""SENTIMENT ANALYSIS USING PYTHON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-BBSborGtKKfrX5gh1xGu7f36aMSkTUI

LOADING DATA
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
linkedin_data = pd.read_csv("linkedin-reviews.csv")

# Display the first few rows of the dataset
print(linkedin_data.head())

"""TRYING TO FIND MORE ABOUT THE DATA

"""

print(linkedin_data.info())

"""EXPLORATORY DATA ANALYSIS"""

# Plotting the distribution of ratings
sns.set(style="whitegrid")
plt.figure(figsize=(9, 5))
sns.countplot(data=linkedin_data, x='Rating')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

# Calculating the length of each review
linkedin_data['Review Length'] = linkedin_data['Review'].apply(len)

# Plotting the distribution of review lengths
plt.figure(figsize=(9, 6))
sns.histplot(linkedin_data['Review Length'], bins=50, kde=True)
plt.title('Distribution of Review Lengths')
plt.xlabel('Length of Review')
plt.ylabel('Count')
plt.show()

pip install textblob

from textblob import TextBlob

def textblob_sentiment_analysis(review):
    # Analyzing the sentiment of the review
    sentiment = TextBlob(review).sentiment
    # Classifying based on polarity
    if sentiment.polarity > 0.1:
        return 'Positive'
    elif sentiment.polarity < -0.1:
        return 'Negative'
    else:
        return 'Neutral'

# Applying TextBlob sentiment analysis to the reviews
linkedin_data['Sentiment'] = linkedin_data['Review'].apply(textblob_sentiment_analysis)

# Displaying the first few rows with the sentiment
print(linkedin_data.head())

# Analyzing the distribution of sentiments
sentiment_distribution = linkedin_data['Sentiment'].value_counts()

# Plotting the distribution of sentiments
plt.figure(figsize=(9, 5))
sns.barplot(x=sentiment_distribution.index, y=sentiment_distribution.values)
plt.title('Distribution of Sentiments')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 5))
sns.countplot(data=linkedin_data, x='Rating', hue='Sentiment')
plt.title('Sentiment Distribution Across Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.legend(title='Sentiment')
plt.show()

from wordcloud import WordCloud

# Function to generate word cloud for each sentiment
def generate_word_cloud(sentiment):
    text = ' '.join(review for review in linkedin_data[linkedin_data['Sentiment'] == sentiment]['Review'])
    wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f'Word Cloud for {sentiment} Reviews')
    plt.axis('off')
    plt.show()

# Generating word clouds for each sentiment
for sentiment in ['Positive', 'Negative', 'Neutral']:
    generate_word_cloud(sentiment)

def sentiment_rating_agreement(row):
    if row['Sentiment'] == 'Positive' and row['Rating'] >= 4:
        return 'Agree'
    elif row['Sentiment'] == 'Negative' and row['Rating'] <= 2:
        return 'Agree'
    elif row['Sentiment'] == 'Neutral' and row['Rating'] == 3:
        return 'Agree'
    else:
        return 'Disagree'

linkedin_data['Agreement'] = linkedin_data.apply(sentiment_rating_agreement, axis=1)

# Visualization
plt.figure(figsize=(8, 5))
sns.countplot(data=linkedin_data, x='Agreement', palette='pastel')
plt.title('Sentiment vs Rating Agreement')
plt.xlabel('Agreement')
plt.ylabel('Count')
plt.show()

# Add review length
linkedin_data['Review Length'] = linkedin_data['Review'].apply(len)
linkedin_data['Word Count'] = linkedin_data['Review'].apply(lambda x: len(str(x).split()))

# Visualize average review length by rating
plt.figure(figsize=(10, 6))
sns.barplot(data=linkedin_data, x='Rating', y='Review Length', palette='coolwarm')
plt.title('Average Review Length by Rating')
plt.ylabel('Avg Review Length')
plt.xlabel('Rating')
plt.show()

# Visualize word count
plt.figure(figsize=(10, 6))
sns.boxplot(data=linkedin_data, x='Rating', y='Word Count', palette='Blues')
plt.title('Word Count Distribution by Rating')
plt.ylabel('Word Count')
plt.xlabel('Rating')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Heuristic: Short, 5-star, positive = possible fake
linkedin_data['Is Fake'] = linkedin_data.apply(lambda row: 1 if row['Review Length'] < 30 and row['Rating'] == 5 and row['Sentiment'] == 'Positive' else 0, axis=1)

# Feature engineering
features = linkedin_data[['Review Length', 'Word Count', 'Rating']]
target = linkedin_data['Is Fake']

# Split
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Model
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluation
print(classification_report(y_test, y_pred))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="YlOrBr")
plt.title('Fake Review Detector - Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

pip install vaderSentiment textblob

from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

vader = SentimentIntensityAnalyzer()

def get_vader_sentiment(text):
    score = vader.polarity_scores(text)['compound']
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

def get_textblob_sentiment(text):
    score = TextBlob(text).sentiment.polarity
    if score > 0.1:
        return 'Positive'
    elif score < -0.1:
        return 'Negative'
    else:
        return 'Neutral'

linkedin_data['TextBlob Sentiment'] = linkedin_data['Review'].apply(get_textblob_sentiment)
linkedin_data['VADER Sentiment'] = linkedin_data['Review'].apply(get_vader_sentiment)

# Compare side-by-side
comparison_df = linkedin_data[['Rating', 'Review', 'TextBlob Sentiment', 'VADER Sentiment']]
print(comparison_df.head())

# Visualization
comparison_counts = pd.crosstab(linkedin_data['TextBlob Sentiment'], linkedin_data['VADER Sentiment'])

plt.figure(figsize=(8, 6))
sns.heatmap(comparison_counts, annot=True, cmap='coolwarm')
plt.title('TextBlob vs VADER Sentiment Comparison')
plt.show()